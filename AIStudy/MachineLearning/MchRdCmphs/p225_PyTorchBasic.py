#深度学习框架PyTorch基础   P244

'''
机器学习基础 P205
按照训练数据中有无输出数据的标注分为监督学习(supervised learning)、无监督学习和半监督学习(semi-supervised learning)
监督学习的训练数据中包括输入范例和对应的输出范例 利用观察和统计输入输出之间的关系训练模型 并通过比对训练结果和标注结果之间的差异调整模型参数 提高预测性能 效果一般较好 但非常依赖标注数据的大小 亦花费大量人力和时间成本
无监督学习指训练数据没有对输出进行标注 需要模型自行定义训练标准 以达预期目标 如聚类 难度远大于监督学习 效果一般也逊于后者 可以有效利用海量未标注数据 特别适合NLP相关应用
半监督学习处理上述两者之间 一种方法是未标注数据进行预训练 通过少量标注数据引导模型进一步提高准确度

模型 建立模型是为了找到自变量房子的d种信息x=(x1,x2,...,xd)与因变量y价格的关系
参数 可能的关系有无数种 通过参数β0,β1...,βd来限定范围 y = β0 + β1x1 + β2x2 +...+ βdxd
     二次模型：y=β(0,0)+∑(i,∑(j,β(1,j)xixj))
不同模型的假设范围大小不一 参数个数和复杂程度也不一样 需要将参数调整到合适的值 训练模型的过程是根据输入和输出不断改变模型参数的取值 以得到具有一定准确度的模型 即参数优化(parameter optimization)

训练集 (training set)模型用于训练的数据
测试集 (test set)推广 泛化 在训练集上检验模型性能无法充分区分模型优劣 因此需要同分布却未出现的数据担当测试集 即关心模型在未见过数据上的推广能力 亦称泛化能力(generalization)
过拟合 (overfitting) 模型本应在训练集上不断提升准确度 却在超过一定的阈值后于训练集上表现越好的模型在测试集上表现越差 即过度拟合了训练数据 导致模型的泛化能力很差
  重要原因 是模型复杂度过高 参数过多 而训练数据的规模相对较小 参数很容易被过度训练而无法推广到训练数据以外的情况
  解决方法 增加训练数据 减小模型复杂度 给参数加正则化等 对于深度学习有丢弃(Dropout)
验证集 (validation set) 为在训练中观察到过拟合现象 将训练集中分出一部分数据作为验证集 验证集准确度有下滑即可中止优化 选出之前验证集表现最好的模型作结果
'''


'''
深度学习基础 P208
深度学习 最重要的基础组成部分是神经网络
神经网络 指按照人类脑部神经元工作原理进行抽象而建立的一种人工智能运算模型 基本组成单元是人工神经元(neuron) 可输入处理及输出信息 由有权重的边相互连接并进行信息传递 大量神经元组成的复杂网络即神经网络
神经元 亦称感知元(perceptron) 神经网络的最小组成单元 包含n条输入信息x=(x1,x2,...,xn)和1条输出信息 信息均为实数 n条边的权重参数w=(w1,w2,...,wn)
     神经元进行加权和处理 U(x;w)=w1x1+w2x2+...+wnxn=∑(n,i+1,wixi)=w^Tx
     为输出更加灵活一般给结果加上截距 S(x;w,b)=U(x,w)+b=W^T+b
     即S(x;w,b)是关于输入(x1,x2,...,xn)的线性函数
     通过激活函数(activation function)g对加权和进行变换 得到最终输出f(x;w,b)=g(S(x;w,b))
激活函数 性质:1)是一个连续可导的一元非线性函数 允许在常数个点上不可导 目的是便于已有的数值优化工具对其进行求导并优化
             2)激活函数和其导数的计算须较为简单 以提高计算效率 因网络中大量参与运算和求导
             3)因神经网络求导中运用到乘积形式的链式法则 激活函数的导数值域需在一个合理的区间中 以防链式法则中导数的绝对值过大或过小
         常见形式:1)sigmoid函数 σ(x)=1/(1+e^-x) S形曲线 x=0时取值0.5 x→+∞时趋向1 x→-∞时趋向0 收敛速度很快 导数σ'(x)=σ(x)(1-σ(x)) 导数值域(0,0.25] 连续可导 运算简单 函数值域和导数值域均为限定区间 最常用的激活函数之一
                 2)tanh函数 双正切函数 tanh(x)=(e^x-e^-x)/(e^x+e^-x) S行曲线 值域(-1,1) x=0时取值0 x→+∞时趋向1 x→-∞时趋向-1 收敛速度很快 导数tanh'(x)=1-tanh^2(x) 导数值域(0,1] 原点对称 零中心化(zero-centered)
                 3)ReLU函数 修正线性单元(Rectified Linear Unit) 小于0时输出0 大于等于0时直接输出ReLU(x)={x,x>=0;0,x<0}=max(x,0) 导数远离零点 可使优化算法对参数进行有效调控 缺点当参数小于0导数永远是0优化算法无法改变参数的值

前馈神经网络 (feedforward neural network) n个神经元共享输入 并经过计算得到n个输出 形成一个层(level) 作为下一层神经元的输入 层与层通过有权重的边进行连接 形成基本的神经网络形式
     组成 第一层:输入层(Input Level) 非神经元 n个输入值 整个网络的外部输入
          最后一层:输出层(Output Level) 输出作为网络的输出
          两者间层:隐藏层(Hidden Level) 之间的层的统称
     所有相邻层之间均由带权边连接 每层神经元个数不必一致 有各自的截距和参数 充分灵活
     计算过程被称作向前传播(forward pass)
     
损失函数 (loss function)训练神经网络的目的在于使其输出符合预期真值(ground truth) 但其参数在初始化时是随机分布的 需要调整网络参数以提高模型表现 一种方法是通过输出和预期真值的差值求导来得到调整参数的方向 但该差值往往不是一个可导数如分类任务中的正确率 于是多由损失函数估算 损失函数是神经网络中所有参数的函数 它刻画了网络输出与预期真值之间的差异 对同一问题损失函数定义不唯一 但需三点性质：
     1.需要关于神经网络中的所有参数可导 2.定义是函数值越小模型准确度越高 3.需要近似表示结果的不准确性
          近似表示:真正的评测标准下对于一个输入网络参数产生结果好于另组网络参数及结果 无需保证损失函数结果最优 但需要大多情况下满足
     常见类型:均方差损失函数 均方差(Mean Squared Error,MSE) “差的平方的平方”的缩写 若预测值与预期真值接近 损失函数值以平方级缩小 适用于回归类(regression)问题
             交叉熵损失函数 如分类任务 取最大分数下标对于网络参数不可导 通过softmax操作将分数变为概率值 交叉熵希望最大化对应类的概率 即最大化可能性的对数 即最小化预测正确类别的概率的对数的相反数 因概率值范围0~1 交叉熵一定是非负数

梯度下降 (gradient descent)神经网络中最常用的优化方法 一种系统的优化方法来更新初始随机的参数 以达到损失函数值不断减小的目的
     梯度 (gradient)对于有多个参数的函数 可求出函数对于每一个参数的导数 这些导数形成的向量称为梯度
          如f(x)=f(x1,x2,...,xn) 每参数导数∂f/∂xi 导数形成的向量∇f(x)|x=(x1,x2,...,xn)=[∂f/∂x1,∂f/∂x2,...,∂f/∂xn]为梯度
     学习率 (learning rate)所有的参数沿着其梯度的反方向移动 距离用学习率α控制 即xi←xi-α(∂f/∂xi)
反向传播 (back propagation)梯度下降法为求出函数当前参数点梯度 即损失函数关于神经网络中所有参数的导数 神经网络结构复杂难以得到每个参数导数公式 遂采用反向传播 利用了微积分中导数计算的链式法则(chain rule)
     链式法则 如果f(g(x))是一个复合函数 即f是g的函数 而g是x的函数 那么f关于x的导数为df(g(x))/dx=(df(g)/dg)(dg(x)/dx)
       例如f(g)=g^2,g(x)=x^3 那么f(g(x))=x^6 所以df(g(x))/dx=6x^5 根据链式法则df(g(x))/dx=(df(g)/dg)(dg(x)/dx)=2g×3x^2=6x^5
       链式法则可以用在神经网络对参数求导的过程中 可得到损失函数关于最后一层边权的导数 继续计算关于前一层边权导数 直到得出全部导数 按学习率沿导数反向移动 以使损失值不断下降
     梯度爆炸 当网络层数变多 导数经过链式法则的乘法操作 很容易在靠近输入层的部分发生导数爆炸和导数消失的情况 多见于多个绝对值大于1的导数或多个绝对值小于1的导数相乘

深度学习中常见神经网络类型 P218
前馈神经网络 (FNN) 如上文 也被称为 全连接网络 (fully connected network) 相邻的两层间全部建立了连接每对神经元的边和权重 因每层神经元个数可能会很庞大 网络规模恐会平方级增长 造成存储空间巨大和运算速度低下 CNN为解决这个问题而设计 
卷积神经网络 (CNN) 最早应用于图像处理 像素的值和周围局部区域像素有关系 即具有局部性(locality) 如果把图像中每个像素最为一层中的一个神经元 那么它应该只和周围一部分神经元进行连接 输入层为I 隐藏层为I×K 每个隐藏层的神经元只和输入层的3×3=9个神经元连接 边权为K 如果依次高亮每个隐藏层神经元连接的输入层神经元 得到一个3×3的方块在输入层移动
    若输入层5×5=25个神经元 隐藏层9个神经元 全连接网络边权共有25×9=225个参数 可将所有隐藏层神经元的9个边权共享(weight sharing) 即统一使用K最为边权参数 便仅仅需要9个边权即可实现两层间的互联 这里称K为过滤器(filter) 这种网络即CNN 因为K和I中每个方块依次相乘并求和的操作类似于数学中的卷积运算
  卷积核 (Convolution Kernel，书中没有的概念) 图像处理时给定输入图像中一个小区域中像素加权平均后成为输出图像中的每个对应像素 其中权值由一个函数定义 这个函数称为卷积核 如卷积公式R(u,v)=∑∑G(u-i,v-j)f(i,j) 其中f为输入G为卷积核
     卷积核kernels：二维的矩阵；滤波器filters：多个卷积核组成的三维矩阵，多出的一维是通道。一个“Kernel”更倾向于是2D的权重矩阵。而“filter”则是指多个Kernel堆叠的3D结构。如果是一个2D的filter，那么两者就是一样的。但是一个3Dfilter，在大多数深度学习的卷积中，它是包含kernel的。每个卷积核都是独一无二的，主要在于强调输入通道的不同方面。(个人理解 类似滤波器 移动的3×3方块即卷积核 需要进一步熟悉)
  输出通道 (output channel) CNN中 也可以用两个不同的过滤器K1、K2生成I×K1和I×K2 称有两个输出通道 如果有多于1个的输入通道(input channel) 如图像中有红蓝绿3个通道 则可将每个输入通道和一份K卷积然后相加 由于输入有3个通道 每个过滤器有3层 与对应的输入进行卷积 得到3个3×3的矩阵 然后将这3个卷积结果进行同位置累加 得到有一个输出通道的3×3的矩阵 若输出通道有2个 则将2个过滤器的结果同时输出
  机器阅读理解中 卷积神经网络常用来进行字符编码处理 即每个长度为L的单词看做一副有1×L个像素的图 每个像素对应一个字符

循环神经网络 (RNN) 专门为深度学习处理变长数据设计的网络结构 对于输入中的每个元素 使用同样的网络结构S并共享参数 并在相邻元素之间进行信息和状态传递 好处在于既减少参数个数 又实现了对任意长度输入序列的处理 且通过信息的传递保留了序列的内在结构 RNN亦称为含上下文的词向量或上下文编码(contextualized embedding) 常用网络结构S:
    门控循环单元 (GRU,Gated Recurrent Unit)是一个网络模块 他接收两个信息作为输入 前一个元素处理后的状态h[t-1]和当前元素x[t] 输出为新的处理状态h[t] GRU中的操作包括激活函数Sigmoid和Tanh 并使用重置门r[t]控制是否忽略上一步元素的处理状态 用更新门z[t]控制是否忽略当前元素 重置门和更新门决定前t个词形成的语句语义是否更多由前面t-1个词决定(忽略当前词向量x[t]) 还是更多由当前词决定(忽略之前状态h[t-1]) 从而生成新的状态h[t]
    长短期记忆 (LSTM Long Short-Term Memory)是更复杂的RNN网络模块 传递细胞状态(cell state)c[i]和隐状态(hidden state)h[i]两种信息 LSTM输入包括上一步传递来的C[i-1]、h[i-1]和当前元素x[t] LSTM内部具有遗忘门f[t]输入门i[t]和输出门o[t] 进行细胞状态和隐状态的选择性使用 输出为新的细胞状态c[t]和隐状态h[i] LSTM网络复杂度比GRU高 参数更多训练时收敛较慢 对于规模较大数据较多问题表现更优
  GRU和LSTM优势 在于减少导数爆炸和导数消失现象 多路径遗忘门结构使得缩短损失函数到参数的平均距离 减少连续相乘导数个数 因此广泛使用
  双向循环神经网络 因单词含义常左右两边相关 双向循环神经网络可认为是对输入文本计算两次RNN 并最终将每个元素的两个RNN状态向量拼接起来形成的最终形态
  多层循环神经网络 RNN层 一层状态可做一层输入元素 形成多层循环神经网络 该结构不断提取文本中更高层次语义 在很多NLP任务中对结果有明显提升

丢弃 (Dropout)
2012年由Hinton等人提出 适用于深度学习的解决过拟合的方法 深度学习模型复杂度一般很高 过拟合现象经常发生
原理 不改变模型的情况下减小模型的复杂度 训练时对于每一批次的数据随机删除网络中一半的隐藏层神经元及其它们相连接的边 包括入边和出边 剩下的网络中计算输出和导数并更新参数 随后恢复所有神经元和连边 下批次训练中 继续随机删除一半的隐藏层神经元
  Dropout以概率p删除网络中的神经元 因训练时每神经元收到大约一半相连神经元输入值 测试阶段要将输入值除以2 每个神经元的输入加权和需要乘以(1-p) 另种方式在训练阶段输入值除以(1-p)测试阶段不用做特殊处理 实际应用时既可用在网络模块 也可作为一个单独的Dropout层作用于输入或中间结果 即层以概率P将向量中每个元素置零
优势 网络结构并没有改变 每批次训练时随机忽略部分节点 等效于每次计算将网络规模减小 实践效果非常好 基本可以替代传统机器学习中参数正则化方法来应对过拟合现象 对Dropout有效解决过拟合现象原因主流观点：
  第一 Dropout应用等价于同时训练了多个不同的模型 最后将他们平均值作为预测值 合并多模型做法相当于集成方法(ensemble method) 是机器学习中一种有效防止过拟合的算法
  第二 Dropout减少神经元之间的共适应关系(coadaptation) 任何两个神经元都有一定概率不会同时出现 所以训练中强化了每个神经元独立计算的能力 从而减少了一个特征需要在其他特征出现时才有用的共适应关系 提高了整个网络的鲁棒性

生成式对抗网络(GAN, Generative Adversative Nets, 对抗神经网络) (补充内容 书中不存在的)
REF:https://blog.csdn.net/u013139259/article/details/52729191
机器学习两个模型 生成模型和判别模型
  生成模型(Generative) 学习到的是对于所观察数据的联合分布 比如2-D:p(x,y)
  判别模型 学习到的是条件概率分布p(y|x) 即学习到的是观察变量x的前提下的非观察变量的分布情况 如监督学习 分类问题
对抗神经网络就是一个判别模型(Discriminative, D)和一个生成模型(Generative ,G)的组成的
对抗名字的由来 D是银行的Teller G是一个Crook专门制造假币 那么其中的对抗过程就是对于D来说不断的学习来进行真币的判断 G则是不断学习制造更像真币的假币来欺骗D 而最后的训练结果则是D可以很好的区分真假币但是G制造了如假包换的假币而D分辨不出
模型 Z→G→G(Z)+X→D→ Z是G的输入 一般情况下是高斯随机分布生成的数据 其中G的输出是G(z) 对于真实的数据 一般都为图片 将分布变量用X(Real Image)来表示 那么对于D的输出则是判断来自X的可能性 是一个常量
训练和优化 对于G来说 要不断的欺骗D 那么也就是max log(D(G(z))) 对于D来说 要不断的学习防止被D欺骗 那么也就是max log(D(x)) + log(1 - D(G(z)))
训练过程 先进行训练D 然后训练G
训练技巧 dropout的使用 每次进行多次D的训练再进行G的训练防止过拟合 训练之前可以先进行预训练
常使用的地方就是图像生成 如超分辨率任务 语义分割等

深度学习框架PyTorch P224 如下
'''

print("=====初始化张量代码示例=====")

import torch
#一个大小为2 x 3的实数型张量
a = torch.FloatTensor([[1.2, 3.4, 5], [3, 6, 7.4]])
print(a)
#一个大小为5 x 6的实数型张量，每个元素根据标准正态分布N(0,1)随机采样
b = torch.randn(5, 6) 
print(b)
#将a第0行第2列的元素改为4.0，变为([[1.2, 3.4, 4.0], [3, 6, 7.4]])
a[0, 2] = 4.0 
print(a)

print("=====运算和求导示例=====")

import torch
a = torch.ones(1)         # 一个1维向量，值为1
#a = a.cuda()              # 将a放入GPU，如果本机没有GPU，注释此句
print(a.requires_grad)           # False
a.requires_grad = True    # 设定a需要计算导数
b = torch.ones(1)
x = 3 * a + b             # x是最终结果
print(x.requires_grad)    # True，因为a需要计算导数，所以x需要计算导数
x.backward()              # 计算所有参数的导数
print(a.grad)                   # tensor([ 3.])，导数为3 

print("=====全连接层示例=====")

import torch.nn as nn
# 四层神经网络，输入层大小为30，两个隐藏层大小为50和70，输出层大小为1
linear1 = nn.Linear(30, 50)
linear2 = nn.Linear(50, 70)
linear3 = nn.Linear(70, 1)
# 10组输入数据作为一批次(batch)，每一个输入为30维
x = torch.randn(10, 30)
# 10组输出数据，每一个输出为1维
res = linear3(linear2(linear1(x)))
print(res)

print("=====丢弃示例=====")

layer = nn.Dropout(0.1)  # Dropout层，置零概率为0.1
input = torch.randn(5, 2)
print(input)
output = layer(input)        # 维度仍为5 x 2，每个元素有10%概率为0
print(output)

print("=====CNN示例=====")

# 卷积神经网络，输入通道有1个，输出通道3个，过滤器大小为5
conv = nn.Conv2d(1, 3, 5)
# 10组输入数据作为一批次(batch)，每一个输入为单通道32 x 32矩阵
x = torch.randn(10, 1, 32, 32)  
# y维度为10 x 3 x 28 x 28，表示输出10组数据，每一个输出为3通道28 x 28矩阵 (28=32-5+1)
y = conv(x)
print(y.shape) # torch.Size([10, 3, 28, 28]

print("=====RNN示例=====")

# 双层GRU输入元素维度是10，状态维度是20，batch是第1维
rnn = nn.GRU(10, 20, num_layers=2)    
# 一批次共3个序列，每个序列长度5，维度是10，注意batch是第1维
x = torch.randn(5, 3, 10) 
# 初始状态，共3个序列，2层，维度是20
h0 = torch.randn(2, 3, 20)
# output是所有的RNN状态，大小为5 x 3 x 20；hn大小为2 x 3 x 20，为RNN最后一个状态
output, hn = rnn(x, h0) 
print(output.shape) # torch.Size([5, 3, 20])
print(hn.shape) # torch.Size([2, 3, 20])
